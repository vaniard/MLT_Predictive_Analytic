# -*- coding: utf-8 -*-
"""Predictive_Analytic_Wine_Quality.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1j3jn2NasWf4HG1IL8GlPng5hJ_6uEO4w

## Import Library
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.style as style
# %matplotlib inline
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, ConfusionMatrixDisplay
from sklearn.metrics import precision_score, recall_score, f1_score
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier

import warnings
warnings.filterwarnings('ignore')

"""## Load Dataset"""

df_wine = pd.read_csv('/content/winequality-red.csv')
df_wine

"""## Data Understanding

**Struktur Data**
"""

print("\nJumlah baris dan kolom: ")
df_wine.shape

"""**Menghitung ukuran dataset**"""

df_wine.size

"""**Mengecek informasi dataset**"""

print("\nInformasi Dataset :")
df_wine.info()

"""* Tipe data pada dataset terdiri dari *float64* dan *int64* hal tersebut menunjukkan bahwa dataset data numerik.
* Terdapat satu kolom target yaitu quality.
"""

df_wine.describe()

"""**Mengecek missing values**"""

print("\nJumlah data yang hilang :")
print(df_wine.isnull().sum())

"""Tidak terdapat missing values atau data yang hilang pada dataset tersebut.

**Mengecek data duplikat**
"""

print("\nJumlah data duplikat :")
print(df_wine.duplicated().sum())

"""Terdapat data duplikat sebanyak 240 dan harus dilakukan pembersihan data yang duplikat.

**Mencecek nilai unik**
"""

df_wine['quality'].value_counts()

"""Sebagian besar data terkonsentrasi pada quality 5 dan 6, kemudian diikuti oleh 7. Quality lebih rendah yaitu 3 dan 4 serta quality yang lebih tinggi yaitu 8 memiliki jumlah sampel yang jauh lebih sedikit.

### Exploratory Data Analysis

**Univariate Analysis**
"""

import os
import math
import matplotlib.pyplot as plt
import pandas as pd

n_cols = 3

n_rows = math.ceil(len(df_wine.columns) / n_cols)

fig, axes = plt.subplots(n_rows, n_cols, figsize=(n_cols * 4, n_rows * 3))

axes = axes.flatten()

for i, col in enumerate(df_wine.columns):
  df_wine[col].hist(bins=10, ax=axes[i], color='orange')
  axes[i].set_title(f'Distribusi {col}')

for j in range(i + 1, len(axes)):
  fig.plt.delaxes(axes[j])

plt.tight_layout()
plt.show()

"""Berdasarkan distribusi diatas, terdapat beberapa fitur seperti *density* dan *pH* memiliki bentuk distribusi yang normal. Akan tetapi pada fitur lainnya, seperti *alcohol*, *residual sugar* memiliki skewed ke kanan dan fitur seperti *chlorides* memiliki skewed ke kiri.

**Bivariete Analysis**
"""

n_cols = 3

n_rows = math.ceil((len(df_wine.columns) - 1) / n_cols)

fig, axes = plt.subplots(n_rows, n_cols, figsize=(n_cols * 6, n_rows * 4))

axes = axes.flatten()

cols = [col for col in df_wine.columns if col != 'quality']

for i, col in enumerate(cols):
  sns.barplot(x='quality', y=col, data=df_wine, ax=axes[i], hue='quality', palette='magma', legend=False)
  axes[i].set_title(f'{col} vs quality')

for j in range(i + 1, len(axes)):
  fig.delaxes(axes[j])

plt.tight_layout()
plt.show()

"""Pada diagram diatas, dapat dilihat bahwa beberapa fitur seperti *alcohol*, *sulphates*, *citric acid* dan *volatile acidity* sangat mempengaruhi kualitas anggur antara baik atau buruk.

**Memeriksa Outlier**
"""

n_cols = 3

n_rows = math.ceil(len(df_wine.columns) / n_cols)

fig, axes = plt.subplots(n_rows, n_cols, figsize=(n_cols * 6, n_rows * 4))

axes = axes.flatten()

for i, col in enumerate(df_wine.columns):
  sns.boxplot(x=col, data=df_wine, ax=axes[i], color='orange')
  axes[i].set_title(f'Boxplot {col}')

for j in range(i + 1, len(axes)):
  fig.delaxes(axes[j])

plt.tight_layout()
plt.show()

"""Boxplot diatas menunjukkan bahwa terdapat beberapa fitur seperti *alcohol* atau *sulphates* memiliki outlier. Maka dari itu perlu dilakukan penganganan outlier pada data processing.

**Correlation Matrix**
"""

plt.figure(figsize=(10, 7))
sns.heatmap(df_wine.corr(), annot=True, cmap='Blues')
plt.title('Correlation Matrix antar Kolom')
plt.show()

"""Berdasarkan correlation matrix diatas, ditunjukkan bahwa fitur seperti *alcohol* dan *sulphates* memiliki korelasi yang tinggi terhadap kualitas anggur.

### Insight

Dataset *red wine* memiliki data yang cukup bersih tanpa adanya missing values, akan tetapi memerlukan penanganan data duplikat dan outlier. Distribusi fitur bervariasi dan terdapat beberapa fitur kunci seperti *alcohol, sulphates, citric acid dan volatile acidity* menunjukkan hubungan yang kuat dengan quality anggur.

## Data Preparation

**Menghapus Data Duplikat**
"""

df_cleaned = df_wine.copy()

df_cleaned = df_cleaned.drop_duplicates()

print("\nJumlah data duplikat yang sudah dihapus : ")
print(df_cleaned.duplicated().sum())

"""**Menangani Outlier**"""

corr = df_wine.corr()['quality'].sort_values(ascending=False)
corr.head(12)

cols_select = corr[abs(corr) > 0.2].index.tolist()
cols_select.remove('quality')
cols_select

for i in cols_select:
  Q1 = df_cleaned[i].quantile(0.25)
  Q3 = df_cleaned[i].quantile(0.75)
  IQR = Q3 - Q1
  df_cleaned = df_cleaned[~((df_cleaned[i] < (Q1 - 1.5 * IQR)) | (df_cleaned[i] > (Q3 + 1.5 * IQR)))]

"""**Transformasi Variabel Quality**"""

df_cleaned['quality'] = pd.cut(df_cleaned['quality'], bins=[0, 4, 6, 10], labels=['buruk', 'sedang', 'baik'])
df_cleaned.head()

df_cleaned['quality'].value_counts()

df_cleaned['quality'] = df_cleaned['quality'].map({'buruk' : 0, 'sedang': 1, 'baik' : 2})

df_cleaned

"""**Split Data**"""

X = df_cleaned.drop('quality', axis=1)
y = df_cleaned['quality']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=14)

"""**Standardisasi Fitur**"""

scaled = StandardScaler()
X_train = scaled.fit_transform(X_train)
X_test = scaled.transform(X_test)

"""### Insight

*   Menghapus 240 data duplikat. Hal ini merupakan langkah penting karena data duplikat dapat menyebabkan bias pada model dan memberikan bobot yang tidak proposional pada sampel yang berulang.
*   Menggunakan korelasi terhadap kolom *quality* sebagar langkah awal untuk memiliki fitur yang akan ditangani outliernya. Dengan memilih kolom yang memiliki korelasi absolut di atas 0.2.
*   Menggunakan metode IQR untuk mendeteksi dan menghapus outlier. Dengan menghapus baris yang mengandung outlier.
*   Mengklasifikasikan variabel quality menjadi tiga kategori yaitu buruk, sedang dan baik. Kemudian melakukana encoding kategori-kategori tersebut menjadi nilai numerik seperti 0, 1, dan 2.
*   Dataset yang sudah bersih dibagi menjadi data training dan data testing dengan perbandingan 80% dan 20%.
*   Menggunakan StandardScaler untuk menstrandarisasi fitur pada data training dan data testing. Standardisasi ini bertujuan untuk mengubah nilai fitur sehingga memiliki rata-rata 0 dan standar deviasi 1.

## Modelling

**Model KNN**
"""

y_predict_list = []

knn_model = KNeighborsClassifier(n_neighbors=5)
knn_model.fit(X_train, y_train)
y_predict = knn_model.predict(X_test)
y_predict_list.append(y_predict)

print(f'Accuracy Score : {accuracy_score(y_test, y_predict)}')

print(f'Confusion Matrix : \n{confusion_matrix(y_test, y_predict)}')

print(f'Classification Report : \n{classification_report(y_test, y_predict)}')

cm_knn = confusion_matrix(y_test, y_predict_list[0])
disp = ConfusionMatrixDisplay(confusion_matrix=cm_knn, display_labels=knn_model.classes_)
disp.plot(cmap=plt.cm.Blues)
plt.title('Confusion Matrix - KNN Model')
plt.show()

"""**Model SVC**"""

from sklearn.svm import  SVC

svc_model = SVC(C=0.1, kernel='rbf', gamma='scale')
svc_model.fit(X_train, y_train)
y_predict = svc_model.predict(X_test)
y_predict_list.append(y_predict)

print(f'Accuracy Score : {accuracy_score(y_test, y_predict)}')

print(f'Confusion Matrix : \n{confusion_matrix(y_test, y_predict)}')

print(f'Classification Report : \n{classification_report(y_test, y_predict, zero_division=0)}')

cm_svc = confusion_matrix(y_test, y_predict_list[1])
disp = ConfusionMatrixDisplay(confusion_matrix=cm_svc, display_labels=svc_model.classes_)
disp.plot(cmap=plt.cm.Blues)
plt.title('Confusion Matrix - SVC Model')
plt.show()

"""**Model Random Forest**"""

rf_model = RandomForestClassifier(n_estimators=100)
rf_model.fit(X_train, y_train)
y_predict = rf_model.predict(X_test)
y_predict_list.append(y_predict)

print(f'Accuracy Score : {accuracy_score(y_test, y_predict)}')

print(f'Confusion Matrix : \n{confusion_matrix(y_test, y_predict)}')

print(f'Classification Report : \n{classification_report(y_test, y_predict, zero_division=0)}')

cm_rf = confusion_matrix(y_test, y_predict_list[2])
disp = ConfusionMatrixDisplay(confusion_matrix=cm_rf, display_labels=rf_model.classes_)
disp.plot(cmap=plt.cm.Blues)
plt.title('Confusion Matrix - Random Forest Model')
plt.show()

"""### Insight

*   Modelling bertujuan untuk melatih dan mengevaluasi kinerja ketiga model yang berbeda yaitu KNN, SCV dan Random Forest dalam memprediksi kualitas anggur berdasarkan data yang sudah diproses sebelumnya.
*   Model diinisialisasi dengan parameter tertentu.
*   Model dilatih menggunakan data training yang sudah distandardisasi.
*   Model digunakan untuk membuat prediksi pada data testing yang sudah distandardisasi yang kemudian hasil prediksinya di simpan.

## Evaluation

**Perbandingan Accuracy Score Model**
"""

# Model KNN
y_predict_list = []

knn_model = KNeighborsClassifier(n_neighbors=5)
knn_model.fit(X_train, y_train)
y_predict = knn_model.predict(X_test)
y_predict_list.append(y_predict)

# Model SVC
from sklearn.svm import  SVC

svc_model = SVC(C=0.1, kernel='rbf', gamma='scale')
svc_model.fit(X_train, y_train)
y_predict = svc_model.predict(X_test)
y_predict_list.append(y_predict)

# Model Random Forest
rf_model = RandomForestClassifier(n_estimators=100)
rf_model.fit(X_train, y_train)
y_predict = rf_model.predict(X_test)
y_predict_list.append(y_predict)

# Evaluation
models = ['KNN', 'SVM', 'Random Forest']
accuracy_scores = [accuracy_score(y_test, y_pred) for y_pred in y_predict_list]

plt.figure(figsize=(8, 6))
sns.barplot(x=models, y=accuracy_scores, palette='viridis')
plt.title('Perbandingan Accuracy Score Model', fontsize=14)
plt.ylabel('Accuracy Score', fontsize=12)
plt.ylim(0, 1)

# Tambahkan teks untuk menampilkan akurasi di bawah plot
for i, accuracy in enumerate(accuracy_scores):
    plt.text(i, accuracy + 0.02, f'{accuracy:.4f}', ha='center', va='bottom')

plt.tight_layout()
plt.show()

# Menampilkan akurasi di output terpisah juga
print("\nHasil Accuracy Score:")
for model, accuracy in zip(models, accuracy_scores):
    print(f"{model}: {accuracy:.4f}")

"""Dari ketiga  model yang dibandingkan
* Random Forest Model menunjukkan performa terbaik dalam hal accuracy score, dengan nilai tertinggi yaitu 0.8780.
* SVM Model berada pada urutan kedua dengan accuracy score 0.8622.
* KNN Model dengan accuracy score terendah diantara ketiganya yaitu 0.8425

Maka dari itu, jika matrik utama adalah accuracy, maka Random Forest Model adalah yang paling baik diantara ketiga model ini pada dataset yang diuji.

**Perbandingan Accuracy, Precision, Recall dan F1-Score**
"""

models = ['KNN', 'SVM', 'Random Forest']

accuracy = [accuracy_score(y_test, y_pred) for y_pred in y_predict_list]
precision = [precision_score(y_test, y_pred, average='weighted', zero_division=0) for y_pred in y_predict_list]
recall = [recall_score(y_test, y_pred, average='weighted', zero_division=0) for y_pred in y_predict_list]
f1 = [f1_score(y_test, y_pred, average='weighted') for y_pred in y_predict_list]

fig, axs = plt.subplots(2, 2, figsize=(12, 8))

metrics = {'Accuracy': accuracy, 'Precision': precision, 'Recall': recall, 'F1-score': f1}

colors = sns.color_palette('viridis', len(models))

for i, (metric_name, metric_values) in enumerate(metrics.items()):
    ax = axs[i // 2, i % 2]
    bars = ax.bar(models, metric_values, color=colors)
    ax.set_title(metric_name)
    ax.set_ylabel(metric_name)
    ax.set_ylim(0.6, .9)
    ax.grid(axis='y', linestyle='--', alpha=0.7)

    for bar in bars:
        yval = bar.get_height()
        ax.text(bar.get_x() + bar.get_width()/2, yval, round(yval, 4), va='bottom', ha='center')

plt.tight_layout()
plt.show()

"""## Conclusion

Accuracy
*   Random Forest memiliki akurasi tertinggi, kemudian diikuti oleh SVM dan juga KNN.

Precision
*  Random Forest juga menunjukkan precision tertinggi dengan score 0.8381.
*  KNN dengan score 0.8177
*  SVM dengan score 0.7434.

Recall
*   Random Forest juga menunjukkan score Recall tertinggi dengan 0.878.
*   SVM dengan score 0.8622.
*   KNN dengan score 0.8425.

F-1 Score
*   Random Forest menunjukkan score 0.8532.
*   KNN berada di posisi kedua dengan score 0.8295.
*   SVM dengan score 0.7984.

Berdasarkan perbandingan keempat metrik evaluasi, **Random Forest** merupakan model yang paling unggul di antaranya ketiganya. Model ini tidak hanya memiliki akurasi yang tinggi tetapi juga menunjukkan keseimbangaan terbaik antara Precision, Recall dan F-1 score. Maka dari itu, **Random Forest** adalah model terbaik untuk memprediksi kualitas anggur berdasarkan hasil evaluasi yang dilakukan.
"""