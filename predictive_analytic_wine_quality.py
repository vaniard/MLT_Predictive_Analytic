# -*- coding: utf-8 -*-
"""Predictive_Analytic_Wine_Quality.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1j3jn2NasWf4HG1IL8GlPng5hJ_6uEO4w

## Import Library
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.style as style
# %matplotlib inline
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, ConfusionMatrixDisplay
from sklearn.metrics import precision_score, recall_score, f1_score
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier

import warnings
warnings.filterwarnings('ignore')

"""## Load Dataset"""

df_wine = pd.read_csv('/content/winequality-red.csv')
df_wine

"""## Data Understanding"""

print("\nJumlah baris dan kolom: ")
df_wine.shape

df_wine.size

print("\nInformasi Dataset :")
df_wine.info()

df_wine.describe()

print("\nJumlah data yang hilang :")
print(df_wine.isnull().sum())

print("\nJumlah data duplikat :")
print(df_wine.duplicated().sum())

"""Terdapat data duplikat sebanyak 240 dan harus dilakukan pembersihan data yang duplikat."""

df_wine['quality'].value_counts()

"""### Exploratory Data Analysis

**Univariate Analysis**
"""

import os
import math
import matplotlib.pyplot as plt
import pandas as pd

n_cols = 3

n_rows = math.ceil(len(df_wine.columns) / n_cols)

fig, axes = plt.subplots(n_rows, n_cols, figsize=(n_cols * 4, n_rows * 3))

axes = axes.flatten()

for i, col in enumerate(df_wine.columns):
  df_wine[col].hist(bins=10, ax=axes[i], color='orange')
  axes[i].set_title(f'Distribusi {col}')

for j in range(i + 1, len(axes)):
  fig.plt.delaxes(axes[j])

plt.tight_layout()
plt.show()

"""Berdasarkan distribusi diatas, terdapat beberapa fitur seperti *density* dan *pH* memiliki bentuk distribusi yang normal. Akan tetapi pada fitur lainnya, seperti *alcohol*, *residual sugar* memiliki skewed ke kanan dan fitur seperti *chlorides* memiliki skewed ke kiri.

**Bivariete Analysis**
"""

n_cols = 3

n_rows = math.ceil((len(df_wine.columns) - 1) / n_cols)

fig, axes = plt.subplots(n_rows, n_cols, figsize=(n_cols * 6, n_rows * 4))

axes = axes.flatten()

cols = [col for col in df_wine.columns if col != 'quality']

for i, col in enumerate(cols):
  sns.barplot(x='quality', y=col, data=df_wine, ax=axes[i], hue='quality', palette='magma', legend=False)
  axes[i].set_title(f'{col} vs quality')

for j in range(i + 1, len(axes)):
  fig.delaxes(axes[j])

plt.tight_layout()
plt.show()

"""Pada diagram diatas, dapat dilihat bahwa beberapa fitur seperti *alcohol*, *sulphates*, *citric acid* dan *volatile acidity* sangat mempengaruhi kualitas anggur antara baik atau buruk.

**Memeriksa Outlier**
"""

n_cols = 3

n_rows = math.ceil(len(df_wine.columns) / n_cols)

fig, axes = plt.subplots(n_rows, n_cols, figsize=(n_cols * 6, n_rows * 4))

axes = axes.flatten()

for i, col in enumerate(df_wine.columns):
  sns.boxplot(x=col, data=df_wine, ax=axes[i], color='orange')
  axes[i].set_title(f'Boxplot {col}')

for j in range(i + 1, len(axes)):
  fig.delaxes(axes[j])

plt.tight_layout()
plt.show()

"""Boxplot diatas menunjukkan bahwa terdapat beberapa fitur seperti *alcohol* atau *sulphates* memiliki outlier. Maka dari itu perlu dilakukan penganganan outlier pada data processing.

**Correlation Matrix**
"""

plt.figure(figsize=(10, 7))
sns.heatmap(df_wine.corr(), annot=True, cmap='Blues')
plt.title('Correlation Matrix antar Kolom')
plt.show()

"""Berdasarkan correlation matrix diatas, ditunjukkan bahwa fitur seperti *alcohol* dan *sulphates* memiliki korelasi yang tinggi terhadap kualitas anggur.

## Data Preparation

**Menghapus Data Duplikat**
"""

df_cleaned = df_wine.copy()

df_cleaned = df_cleaned.drop_duplicates()

print("\nJumlah data duplikat yang sudah dihapus : ")
print(df_cleaned.duplicated().sum())

"""**Menangani Outlier**"""

corr = df_wine.corr()['quality'].sort_values(ascending=False)
corr.head(12)

cols_select = corr[abs(corr) > 0.2].index.tolist()
cols_select.remove('quality')
cols_select

for i in cols_select:
  Q1 = df_cleaned[i].quantile(0.25)
  Q3 = df_cleaned[i].quantile(0.75)
  IQR = Q3 - Q1
  df_cleaned = df_cleaned[~((df_cleaned[i] < (Q1 - 1.5 * IQR)) | (df_cleaned[i] > (Q3 + 1.5 * IQR)))]

df_cleaned['quality'] = pd.cut(df_cleaned['quality'], bins=[0, 4, 6, 10], labels=['buruk', 'sedang', 'baik'])
df_cleaned.head()

df_cleaned['quality'].value_counts()

df_cleaned['quality'] = df_cleaned['quality'].map({'buruk' : 0, 'sedang': 1, 'baik' : 2})

df_cleaned

X = df_cleaned.drop('quality', axis=1)
y = df_cleaned['quality']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=14)

scaled = StandardScaler()
X_train = scaled.fit_transform(X_train)
X_test = scaled.transform(X_test)

"""## Modelling

**Model KNN**
"""

y_predict_list = []

knn_model = KNeighborsClassifier(n_neighbors=5)
knn_model.fit(X_train, y_train)
y_predict = knn_model.predict(X_test)
y_predict_list.append(y_predict)

print(f'Accuracy Score : {accuracy_score(y_test, y_predict)}')

print(f'Confusion Matrix : \n{confusion_matrix(y_test, y_predict)}')

print(f'Classification Report : \n{classification_report(y_test, y_predict)}')

cm_knn = confusion_matrix(y_test, y_predict_list[0])
disp = ConfusionMatrixDisplay(confusion_matrix=cm_knn, display_labels=knn_model.classes_)
disp.plot(cmap=plt.cm.Blues)
plt.title('Confusion Matrix - KNN Model')
plt.show()

"""**Model SVC**"""

from sklearn.svm import  SVC

svc_model = SVC(C=0.1, kernel='rbf', gamma='scale')
svc_model.fit(X_train, y_train)
y_predict = svc_model.predict(X_test)
y_predict_list.append(y_predict)

print(f'Accuracy Score : {accuracy_score(y_test, y_predict)}')

print(f'Confusion Matrix : \n{confusion_matrix(y_test, y_predict)}')

print(f'Classification Report : \n{classification_report(y_test, y_predict, zero_division=0)}')

cm_svc = confusion_matrix(y_test, y_predict_list[1])
disp = ConfusionMatrixDisplay(confusion_matrix=cm_svc, display_labels=svc_model.classes_)
disp.plot(cmap=plt.cm.Blues)
plt.title('Confusion Matrix - SVC Model')
plt.show()

"""**Model Random Forest**"""

rf_model = RandomForestClassifier(n_estimators=100)
rf_model.fit(X_train, y_train)
y_predict = rf_model.predict(X_test)
y_predict_list.append(y_predict)

print(f'Accuracy Score : {accuracy_score(y_test, y_predict)}')

print(f'Confusion Matrix : \n{confusion_matrix(y_test, y_predict)}')

print(f'Classification Report : \n{classification_report(y_test, y_predict, zero_division=0)}')

cm_rf = confusion_matrix(y_test, y_predict_list[2])
disp = ConfusionMatrixDisplay(confusion_matrix=cm_rf, display_labels=rf_model.classes_)
disp.plot(cmap=plt.cm.Blues)
plt.title('Confusion Matrix - Random Forest Model')
plt.show()

"""## Evaluation"""

# Model KNN
y_predict_list = []

knn_model = KNeighborsClassifier(n_neighbors=5)
knn_model.fit(X_train, y_train)
y_predict = knn_model.predict(X_test)
y_predict_list.append(y_predict)

# Model SVC
from sklearn.svm import  SVC

svc_model = SVC(C=0.1, kernel='rbf', gamma='scale')
svc_model.fit(X_train, y_train)
y_predict = svc_model.predict(X_test)
y_predict_list.append(y_predict)

# Model Random Forest
rf_model = RandomForestClassifier(n_estimators=100)
rf_model.fit(X_train, y_train)
y_predict = rf_model.predict(X_test)
y_predict_list.append(y_predict)

# Evaluation
models = ['KNN', 'SVM', 'Random Forest']
accuracy_scores = [accuracy_score(y_test, y_pred) for y_pred in y_predict_list]

plt.figure(figsize=(8, 6))
sns.barplot(x=models, y=accuracy_scores, palette='viridis')
plt.title('Perbandingan Accuracy Score Model', fontsize=14)
plt.ylabel('Accuracy Score', fontsize=12)
plt.ylim(0, 1)

# Tambahkan teks untuk menampilkan akurasi di bawah plot
for i, accuracy in enumerate(accuracy_scores):
    plt.text(i, accuracy + 0.02, f'{accuracy:.4f}', ha='center', va='bottom')

plt.tight_layout()
plt.show()

# Menampilkan akurasi di output terpisah juga
print("\nHasil Accuracy Score:")
for model, accuracy in zip(models, accuracy_scores):
    print(f"{model}: {accuracy:.4f}")

"""## Conclusion

Dari ketiga  model yang dibandingkan
* Random Forest Model menunjukkan performa terbaik dalam hal accuracy score, dengan nilai tertinggi yaitu 0.8780.
* SVM Model berada pada urutan kedua dengan accuracy score 0.8622.
* KNN Model dengan accuracy score terendah diantara ketiganya yaitu 0.8425

Maka dari itu, jika matrik utama adalah accuracy, maka Random Forest Model adalah yang paling baik diantara ketiga model ini pada dataset yang diuji.
"""